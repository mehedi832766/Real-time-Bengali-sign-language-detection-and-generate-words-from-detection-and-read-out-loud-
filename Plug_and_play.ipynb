{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mehedi832766/Real-time-Bengali-sign-language-detection-and-generate-words-from-detection-and-read-out-loud-/blob/main/Plug_and_play.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CI9hoWfSbQdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34159a68-9c57-4ab9-e838-382e51645f06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/Plug_Play"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lFx9yUTbRYy",
        "outputId": "47eb6108-c266-4e03-a8ea-5ea16cc4de85"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Plug_Play\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gTTS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7X79C9Ucgst",
        "outputId": "7a6aca35-8f80-4863-9774-3365c2dda806"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gTTS\n",
            "  Downloading gTTS-2.3.1-py3-none-any.whl (28 kB)\n",
            "Collecting requests<3,>=2.27\n",
            "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 KB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.8/dist-packages (from gTTS) (7.1.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.27->gTTS) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.27->gTTS) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.27->gTTS) (3.0.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.27->gTTS) (1.24.3)\n",
            "Installing collected packages: requests, gTTS\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.25.1\n",
            "    Uninstalling requests-2.25.1:\n",
            "      Successfully uninstalled requests-2.25.1\n",
            "Successfully installed gTTS-2.3.1 requests-2.28.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFPr_Z-0TCY9"
      },
      "source": [
        "# 7.1 Webcam Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Y_SSSnf_TAB4"
      },
      "outputs": [],
      "source": [
        "# import dependencies\n",
        "# Import the required module for text\n",
        "# to speech conversion\n",
        "from gtts import gTTS\n",
        "from IPython.display import Audio, display\n",
        "import os\n",
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from google.colab.patches import cv2_imshow\n",
        "from base64 import b64decode, b64encode\n",
        "import PIL\n",
        "import io\n",
        "import html\n",
        "# function to convert the JavaScript object into an OpenCV image\n",
        "def js_to_image(js_reply):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          js_reply: JavaScript object containing image from webcam\n",
        "  Returns:\n",
        "          img: OpenCV BGR image\n",
        "  \"\"\"\n",
        "  # decode base64 image\n",
        "  image_bytes = b64decode(js_reply.split(',')[1])\n",
        "  # convert bytes to numpy array\n",
        "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "  # decode numpy array into OpenCV BGR image\n",
        "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "\n",
        "  return img\n",
        "\n",
        "# function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream\n",
        "def bbox_to_bytes(bbox_array):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n",
        "  Returns:\n",
        "        bytes: Base64 image byte string\n",
        "  \"\"\"\n",
        "  # convert array into PIL image\n",
        "  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n",
        "  iobuf = io.BytesIO()\n",
        "  # format bbox into png for return\n",
        "  bbox_PIL.save(iobuf, format='png')\n",
        "  # format return string\n",
        "  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n",
        "\n",
        "  return bbox_bytes\n",
        "\n",
        "\n",
        "# JavaScript to properly create our live video stream using our webcam as input\n",
        "def video_stream():\n",
        "  js = Javascript('''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "    var labelElement;\n",
        "    \n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "    \n",
        "    function removeDom() {\n",
        "       stream.getVideoTracks()[0].stop();\n",
        "       video.remove();\n",
        "       div.remove();\n",
        "       video = null;\n",
        "       div = null;\n",
        "       stream = null;\n",
        "       imgElement = null;\n",
        "       captureCanvas = null;\n",
        "       labelElement = null;\n",
        "    }\n",
        "    \n",
        "    function onAnimationFrame() {\n",
        "      if (!shutdown) {\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "      }\n",
        "      if (pendingResolve) {\n",
        "        var result = \"\";\n",
        "        if (!shutdown) {\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
        "        }\n",
        "        var lp = pendingResolve;\n",
        "        pendingResolve = null;\n",
        "        lp(result);\n",
        "      }\n",
        "    }\n",
        "    \n",
        "    async function createDom() {\n",
        "      if (div !== null) {\n",
        "        return stream;\n",
        "      }\n",
        "\n",
        "      div = document.createElement('div');\n",
        "      div.style.border = '2px solid black';\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '600px';\n",
        "      document.body.appendChild(div);\n",
        "      \n",
        "      const modelOut = document.createElement('div');\n",
        "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
        "      labelElement = document.createElement('span');\n",
        "      labelElement.innerText = 'No data';\n",
        "      labelElement.style.fontWeight = 'bold';\n",
        "      modelOut.appendChild(labelElement);\n",
        "      div.appendChild(modelOut);\n",
        "           \n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      video.width = div.clientWidth - 6;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { shutdown = true; };\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\n",
        "          {video: { facingMode: \"environment\"}});\n",
        "      div.appendChild(video);\n",
        "\n",
        "      imgElement = document.createElement('img');\n",
        "      imgElement.style.position = 'absolute';\n",
        "      imgElement.style.zIndex = 1;\n",
        "      imgElement.onclick = () => { shutdown = true; };\n",
        "      div.appendChild(imgElement);\n",
        "      \n",
        "      const instruction = document.createElement('div');\n",
        "      instruction.innerHTML = \n",
        "          '<span style=\"color: red; font-weight: bold;\">' +\n",
        "          'When finished, click here or on the video to stop this demo</span>';\n",
        "      div.appendChild(instruction);\n",
        "      instruction.onclick = () => { shutdown = true; };\n",
        "      \n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      captureCanvas = document.createElement('canvas');\n",
        "      captureCanvas.width = 640; //video.videoWidth;\n",
        "      captureCanvas.height = 480; //video.videoHeight;\n",
        "      window.requestAnimationFrame(onAnimationFrame);\n",
        "      \n",
        "      return stream;\n",
        "    }\n",
        "    async function stream_frame(label, imgData) {\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "\n",
        "      var preCreate = Date.now();\n",
        "      stream = await createDom();\n",
        "      \n",
        "      var preShow = Date.now();\n",
        "      if (label != \"\") {\n",
        "        labelElement.innerHTML = label;\n",
        "      }\n",
        "            \n",
        "      if (imgData != \"\") {\n",
        "        var videoRect = video.getClientRects()[0];\n",
        "        imgElement.style.top = videoRect.top + \"px\";\n",
        "        imgElement.style.left = videoRect.left + \"px\";\n",
        "        imgElement.style.width = videoRect.width + \"px\";\n",
        "        imgElement.style.height = videoRect.height + \"px\";\n",
        "        imgElement.src = imgData;\n",
        "      }\n",
        "      \n",
        "      var preCapture = Date.now();\n",
        "      var result = await new Promise(function(resolve, reject) {\n",
        "        pendingResolve = resolve;\n",
        "      });\n",
        "      shutdown = false;\n",
        "      \n",
        "      return {'create': preShow - preCreate, \n",
        "              'show': preCapture - preShow, \n",
        "              'capture': Date.now() - preCapture,\n",
        "              'img': result};\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "  display(js)\n",
        "  \n",
        "def video_frame(label, bbox):\n",
        "  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n",
        "  return data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# filtered = ['UN', 'BI', 'joint']\n",
        "filtered = ''\n",
        "opt  = {\n",
        "    \n",
        "    \"weights\": \"/content/drive/MyDrive/Plug_Play/best.pt\", # Path to weights file default weights are for nano model\n",
        "    \"yaml\"   : \"/content/drive/MyDrive/Plug_Play/custom.yaml\",\n",
        "    \"img-size\": 640, # default image size\n",
        "    \"conf-thres\": 0.35, # confidence threshold for inference.\n",
        "    \"iou-thres\" : 0.50, # NMS IoU threshold for inference.\n",
        "    \"device\" : '0',  # device to run our model i.e. 0 or 0,1,2,3 or cpu\n",
        "    \"classes\" : filtered  # list of classes to filter or None\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "kF-Y82WHSUOt"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "0vJhL9lvZHMP",
        "outputId": "e0804e13-7a12-433a-c380-fd6026d58697"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Plug_Play/yolov7'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cd yolov7"
      ],
      "metadata": {
        "id": "7YU4nmsdGwh9"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import time\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.backends.cudnn as cudnn\n",
        "from numpy import random\n",
        "\n",
        "from models.experimental import attempt_load\n",
        "from utils.datasets import LoadStreams, LoadImages\n",
        "from utils.general import check_img_size, check_requirements, check_imshow, non_max_suppression, apply_classifier, \\\n",
        "    scale_coords, xyxy2xywh, strip_optimizer, set_logging, increment_path\n",
        "from utils.plots import plot_one_box\n",
        "from utils.torch_utils import select_device, load_classifier, time_synchronized, TracedModel\n",
        "\n",
        "\n",
        "def letterbox(img, new_shape=(640, 640), color=(114, 114, 114), auto=True, scaleFill=False, scaleup=True, stride=32):\n",
        "    # Resize and pad image while meeting stride-multiple constraints\n",
        "    shape = img.shape[:2]  # current shape [height, width]\n",
        "    if isinstance(new_shape, int):\n",
        "        new_shape = (new_shape, new_shape)\n",
        "\n",
        "    # Scale ratio (new / old)\n",
        "    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\n",
        "    if not scaleup:  # only scale down, do not scale up (for better test mAP)\n",
        "        r = min(r, 1.0)\n",
        "\n",
        "    # Compute padding\n",
        "    ratio = r, r  # width, height ratios\n",
        "    new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))\n",
        "    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # wh padding\n",
        "    if auto:  # minimum rectangle\n",
        "        dw, dh = np.mod(dw, stride), np.mod(dh, stride)  # wh padding\n",
        "    elif scaleFill:  # stretch\n",
        "        dw, dh = 0.0, 0.0\n",
        "        new_unpad = (new_shape[1], new_shape[0])\n",
        "        ratio = new_shape[1] / shape[1], new_shape[0] / shape[0]  # width, height ratios\n",
        "\n",
        "    dw /= 2  # divide padding into 2 sides\n",
        "    dh /= 2\n",
        "\n",
        "    if shape[::-1] != new_unpad:  # resize\n",
        "        img = cv2.resize(img, new_unpad, interpolation=cv2.INTER_LINEAR)\n",
        "    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))\n",
        "    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))\n",
        "    img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  # add border\n",
        "    return img, ratio, (dw, dh)"
      ],
      "metadata": {
        "id": "6yQIForFTL_K"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr=[]"
      ],
      "metadata": {
        "id": "7aRN9R0DsSZl"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rOL(l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "pV3x_2f2v18_",
        "outputId": "41635c24-f0a2-4906-bb21-76f3ab5d46b1"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[24, 24, 23, 38, 23, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 23, 38, 38, 38, 23, 23, 23, 23, 23, 20, 20]\n",
            "ভধবন\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.lib.display.Audio object>"
            ],
            "text/html": [
              "\n",
              "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
              "                    <source src=\"data:audio/x-wav;base64,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\" type=\"audio/x-wav\" />\n",
              "                    Your browser does not support the audio element.\n",
              "                </audio>\n",
              "              "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def rOL(s1):\n",
        "  names= ['অ', 'আ', 'ই', 'উ', 'এ', \n",
        "        'ও','ক', 'খ', 'গ', 'ঘ', 'চ', \n",
        "        'ছ', 'জ', 'ঝ', 'ট', 'ঠ', 'ড', \n",
        "        'ঢ', 'ত', 'থ', 'ন', 'প', 'ফ', \n",
        "        'ব', 'ভ', 'ম', 'য়', 'র', 'ল', \n",
        "        'স', 'হ', 'ড়', 'UN', 'BI', 'joint', \n",
        "        'space', 'stop', 'দ', 'ধ']\n",
        "  print(s1)\n",
        "  tr=s1\n",
        "  list2=[]\n",
        "  for i in range(len(s1)):\n",
        "      if(len(list2)==0):\n",
        "        list2.append(s1[i])\n",
        "      elif((s1[i]!=list2[(len(list2))-1])):\n",
        "\n",
        "          if(len(list2)>=2):\n",
        "              if(s1[i]!=s1[i-2]):\n",
        "                list2.append(s1[i])\n",
        "              else:\n",
        "                del list2[-1]\n",
        "          else: \n",
        "            list2.append(s1[i])\n",
        "  str1=\"\"    \n",
        "  for ele in list2:\n",
        "      str1 += names[ele]\n",
        "  print(str1)\n",
        "\n",
        "  myobj = gTTS(text=str1, lang='bn', slow=True)\n",
        "  myobj.save(\"/content/welcome.wav\")\n",
        "  sound_file = '/content/welcome.wav'\n",
        "\n",
        "  return display(Audio(sound_file, autoplay=True))"
      ],
      "metadata": {
        "id": "MvGt1sot5Rey"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "Kkqh_CYnTE-f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "1de00401-5f73-4890-cf9d-4e75b3096a63"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    var video;\n",
              "    var div = null;\n",
              "    var stream;\n",
              "    var captureCanvas;\n",
              "    var imgElement;\n",
              "    var labelElement;\n",
              "    \n",
              "    var pendingResolve = null;\n",
              "    var shutdown = false;\n",
              "    \n",
              "    function removeDom() {\n",
              "       stream.getVideoTracks()[0].stop();\n",
              "       video.remove();\n",
              "       div.remove();\n",
              "       video = null;\n",
              "       div = null;\n",
              "       stream = null;\n",
              "       imgElement = null;\n",
              "       captureCanvas = null;\n",
              "       labelElement = null;\n",
              "    }\n",
              "    \n",
              "    function onAnimationFrame() {\n",
              "      if (!shutdown) {\n",
              "        window.requestAnimationFrame(onAnimationFrame);\n",
              "      }\n",
              "      if (pendingResolve) {\n",
              "        var result = \"\";\n",
              "        if (!shutdown) {\n",
              "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
              "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
              "        }\n",
              "        var lp = pendingResolve;\n",
              "        pendingResolve = null;\n",
              "        lp(result);\n",
              "      }\n",
              "    }\n",
              "    \n",
              "    async function createDom() {\n",
              "      if (div !== null) {\n",
              "        return stream;\n",
              "      }\n",
              "\n",
              "      div = document.createElement('div');\n",
              "      div.style.border = '2px solid black';\n",
              "      div.style.padding = '3px';\n",
              "      div.style.width = '100%';\n",
              "      div.style.maxWidth = '600px';\n",
              "      document.body.appendChild(div);\n",
              "      \n",
              "      const modelOut = document.createElement('div');\n",
              "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
              "      labelElement = document.createElement('span');\n",
              "      labelElement.innerText = 'No data';\n",
              "      labelElement.style.fontWeight = 'bold';\n",
              "      modelOut.appendChild(labelElement);\n",
              "      div.appendChild(modelOut);\n",
              "           \n",
              "      video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      video.width = div.clientWidth - 6;\n",
              "      video.setAttribute('playsinline', '');\n",
              "      video.onclick = () => { shutdown = true; };\n",
              "      stream = await navigator.mediaDevices.getUserMedia(\n",
              "          {video: { facingMode: \"environment\"}});\n",
              "      div.appendChild(video);\n",
              "\n",
              "      imgElement = document.createElement('img');\n",
              "      imgElement.style.position = 'absolute';\n",
              "      imgElement.style.zIndex = 1;\n",
              "      imgElement.onclick = () => { shutdown = true; };\n",
              "      div.appendChild(imgElement);\n",
              "      \n",
              "      const instruction = document.createElement('div');\n",
              "      instruction.innerHTML = \n",
              "          '<span style=\"color: red; font-weight: bold;\">' +\n",
              "          'When finished, click here or on the video to stop this demo</span>';\n",
              "      div.appendChild(instruction);\n",
              "      instruction.onclick = () => { shutdown = true; };\n",
              "      \n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      captureCanvas = document.createElement('canvas');\n",
              "      captureCanvas.width = 640; //video.videoWidth;\n",
              "      captureCanvas.height = 480; //video.videoHeight;\n",
              "      window.requestAnimationFrame(onAnimationFrame);\n",
              "      \n",
              "      return stream;\n",
              "    }\n",
              "    async function stream_frame(label, imgData) {\n",
              "      if (shutdown) {\n",
              "        removeDom();\n",
              "        shutdown = false;\n",
              "        return '';\n",
              "      }\n",
              "\n",
              "      var preCreate = Date.now();\n",
              "      stream = await createDom();\n",
              "      \n",
              "      var preShow = Date.now();\n",
              "      if (label != \"\") {\n",
              "        labelElement.innerHTML = label;\n",
              "      }\n",
              "            \n",
              "      if (imgData != \"\") {\n",
              "        var videoRect = video.getClientRects()[0];\n",
              "        imgElement.style.top = videoRect.top + \"px\";\n",
              "        imgElement.style.left = videoRect.left + \"px\";\n",
              "        imgElement.style.width = videoRect.width + \"px\";\n",
              "        imgElement.style.height = videoRect.height + \"px\";\n",
              "        imgElement.src = imgData;\n",
              "      }\n",
              "      \n",
              "      var preCapture = Date.now();\n",
              "      var result = await new Promise(function(resolve, reject) {\n",
              "        pendingResolve = resolve;\n",
              "      });\n",
              "      shutdown = false;\n",
              "      \n",
              "      return {'create': preShow - preCreate, \n",
              "              'show': preCapture - preShow, \n",
              "              'capture': Date.now() - preCapture,\n",
              "              'img': result};\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n"
          ]
        }
      ],
      "source": [
        "# start streaming video from webcam\n",
        "video_stream()\n",
        "# label for video\n",
        "label_html = 'Capturing...'\n",
        "# initialze bounding box to empty\n",
        "bbox = ''\n",
        "count = 0 \n",
        "s1=[]\n",
        "with torch.no_grad():\n",
        "  weights, imgsz = opt['weights'], (480,640)\n",
        "  set_logging()\n",
        "  device = select_device(opt['device'])\n",
        "  half = device.type != 'cpu'\n",
        "  model = attempt_load(weights, map_location=device)  # load FP32 model\n",
        "  stride = int(model.stride.max())  # model stride\n",
        "\n",
        "  if half:\n",
        "    model.half()\n",
        "\n",
        "  names = model.module.names if hasattr(model, 'module') else model.names\n",
        "  colors = [[random.randint(0, 255) for _ in range(3)] for _ in names]\n",
        "  if device.type != 'cpu':\n",
        "    model(torch.zeros(1, 3, imgsz[0], imgsz[1]).to(device).type_as(next(model.parameters())))\n",
        "  classes = None\n",
        "  if opt['classes']:\n",
        "    classes = []\n",
        "    for class_name in opt['classes']:\n",
        "      classes.append(opt['classes'].index(class_name))\n",
        "  \n",
        "  while True:\n",
        "    js_reply = video_frame(label_html, bbox)\n",
        "    if not js_reply:\n",
        "        break\n",
        "    \n",
        "    img0 = js_to_image(js_reply[\"img\"])\n",
        "    bbox_array = np.zeros([480,640,4], dtype=np.uint8)\n",
        "    img = letterbox(img0, imgsz, stride=stride)[0]\n",
        "    img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, to 3x416x416\n",
        "    img = np.ascontiguousarray(img)\n",
        "    img = torch.from_numpy(img).to(device)\n",
        "    img = img.half() if half else img.float()  # uint8 to fp16/32\n",
        "    img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
        "    if img.ndimension() == 3:\n",
        "      img = img.unsqueeze(0)\n",
        "\n",
        "    # Inference\n",
        "    t1 = time_synchronized()\n",
        "    pred = model(img, augment= False)[0]\n",
        "    \n",
        "    # Apply NMS\n",
        "    pred = non_max_suppression(pred, opt['conf-thres'], opt['iou-thres'], classes= classes, agnostic= False)\n",
        "    t2 = time_synchronized()\n",
        "    for i, det in enumerate(pred):\n",
        "      s = ''\n",
        "      s += '%gx%g ' % img.shape[2:]  # print string\n",
        "      gn = torch.tensor(img0.shape)[[1, 0, 1, 0]]\n",
        "      if len(det):\n",
        "        det[:, :4] = scale_coords(img.shape[2:], det[:, :4], img0.shape).round()\n",
        "\n",
        "        for c in det[:, -1].unique():\n",
        "          n = (det[:, -1] == c).sum()  # detections per class\n",
        "          s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \"  # add to string\n",
        "        \n",
        "        for *xyxy, conf, cls in reversed(det):\n",
        "          label = f'{names[int(cls)]} {conf:.2f}'\n",
        "          if(names[int(cls)]!='space'):\n",
        "            # if(len(s1)>=2):\n",
        "            #   if(int(cls)!=s1[len(s1)-2]):\n",
        "            #     s1.append(int(cls))\n",
        "            #   else:\n",
        "            #     del s1[-1]\n",
        "            # else: \n",
        "              s1.append(int(cls))\n",
        "\n",
        "          elif((names[int(cls)]=='space') and (len(s1)!=0)):\n",
        "            rOL(s1)\n",
        "            s1.clear()\n",
        "          plot_one_box(xyxy, bbox_array, label=label, color=colors[int(cls)], line_thickness=3)\n",
        "          \n",
        "    bbox_array[:,:,3] = (bbox_array.max(axis = 2) > 0 ).astype(int) * 255\n",
        "    bbox_bytes = bbox_to_bytes(bbox_array)\n",
        "    \n",
        "    bbox = bbox_bytes\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l=[24, 24, 23, 38, 23, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 23, 38, 38, 38, 23, 23, 23, 23, 23, 20, 20]"
      ],
      "metadata": {
        "id": "hAc13DAyswTJ"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r='কা, খা, গা, ঘা, চা, ছা, জা, ঝা, টা, ঠা, ডা, ঢা, তা, থা, দা, ধা, না, পা, ফা, বা, ভা, মা, য়া, রা, লা, সা, হা, ড়া'"
      ],
      "metadata": {
        "id": "TeGN5oJvs0PS"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a=r.split(', ')"
      ],
      "metadata": {
        "id": "nUFZVBzmBM6e"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAW3zX-zBTf6",
        "outputId": "37b36c4c-e59c-4c90-8a7a-decfeb86bb15"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "e='কি, খি, গি, ঘি, চি, ছি, জি, ঝি, টি, ঠি, ডি, ঢি, তি, থি, দি, ধি, নি, পি, ফি, বি, ভি, মি, য়ি, রি, লি, সি, হি, ড়ি'"
      ],
      "metadata": {
        "id": "9F2zMpOgBglq"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "e=e.split(', ')"
      ],
      "metadata": {
        "id": "5I6mBgkTBzcr"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "febc546d-fc21-4489-ab87-91b96d6f69e3",
        "id": "eE05n_M-Bzcs"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "u='কু, খু, গু, ঘু, চু, ছু, জু, ঝু, টু, ঠু, ডু, ঢু, তু, থু, দু, ধু, নু, পু, ফু, বু, ভু, মু, য়ু, রু, লু, সু, ড়ু, হু'"
      ],
      "metadata": {
        "id": "34ES2QZZCGTn"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "u=u.split(', ')"
      ],
      "metadata": {
        "id": "yf8GWNkfCGTn"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(u)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f1e3454-9da8-44c6-e81d-01ad12b8019f",
        "id": "GkPLL-BgCGTn"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    }
  ]
}